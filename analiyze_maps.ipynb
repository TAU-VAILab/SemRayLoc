{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "# Method to extract camera number from file name\n",
    "def extract_camera_number(file_name):\n",
    "    match = re.search(r'\\d+', file_name)  # Find the first number in the file name\n",
    "    if match:\n",
    "        return int(match.group())  # Convert the matched number to an integer\n",
    "    return float('inf')  # If no number is found, assign a very high number (or handle differently)\n",
    "\n",
    "# Function to load a compressed tensor\n",
    "def load_compressed_tensor(file_path):\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        tensor = torch.load(f)\n",
    "    return tensor\n",
    "\n",
    "# Function to read poses from a file\n",
    "def read_poses(file_path):\n",
    "    poses = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            x, y, _ = map(float, line.strip().split())\n",
    "            poses.append((x, y))\n",
    "    return poses\n",
    "\n",
    "# Function to plot a single map using the provided method\n",
    "def plot_single_map(prob_map, occ, true_pose, H, W, resolution, title, ax):\n",
    "    prob_map = prob_map.astype(np.float32)\n",
    "    prob_map = np.flipud(cv2.resize(prob_map, (prob_map.shape[1] * 10, prob_map.shape[0] * 10), interpolation=cv2.INTER_LINEAR))\n",
    "    H = prob_map.shape[0]\n",
    "    W = prob_map.shape[1]\n",
    "    ax.imshow(prob_map, extent=[0, W, 0, H], cmap='viridis', alpha=0.6, origin='lower')\n",
    "\n",
    "    # Find all positions with the maximum value\n",
    "    max_value = np.max(prob_map)\n",
    "    max_positions = list(zip(*np.where(prob_map == max_value)))  # List of (y, x) positions\n",
    "\n",
    "    # Randomly select one position among the maxima\n",
    "    random_max_y, random_max_x = random.choice(max_positions)\n",
    "\n",
    "    # Add a red dot at the randomly selected maximum of the map\n",
    "    ax.plot(random_max_x, random_max_y, 'o', markeredgecolor='red', markerfacecolor='none', markersize=10, label='Max Value', alpha=0.8)\n",
    "\n",
    "\n",
    "    # Add a green dot for the true pose\n",
    "    if true_pose:\n",
    "        true_pose_x = true_pose[0] * (1 / resolution) * 10\n",
    "        true_pose_y = H - true_pose[1] * (1 / resolution) * 10\n",
    "        ax.plot(true_pose_x, true_pose_y, 'o', markeredgecolor='green', markerfacecolor='none', markersize=10, label='True Pose', alpha=0.8)\n",
    "\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.axis('off')\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "# Modified Function to Plot Camera Heatmaps with Combinations\n",
    "def plot_camera_heatmaps_with_combination(scene_dir, poses, num_cameras=5):\n",
    "    # Collect all heatmaps\n",
    "    heatmaps = []\n",
    "\n",
    "    for file_name in os.listdir(scene_dir):\n",
    "        if file_name.endswith(\"pred_depth_prob_vol.pt.gz\"):  # Filter for depth_prob_vol files\n",
    "            file_path = os.path.join(scene_dir, file_name)\n",
    "            # Load the tensor\n",
    "            depth_prob_vol = load_compressed_tensor(file_path)\n",
    "            # Take the max over the O dimension (dim=2)\n",
    "            depth_heatmap = depth_prob_vol.max(dim=2).values.numpy()\n",
    "            # Compute the 95th percentile threshold\n",
    "            threshold_0_05 = np.percentile(depth_heatmap, 99.9)\n",
    "            threshold_0_1 = np.percentile(depth_heatmap, 99)\n",
    "            \n",
    "            # Top maps for visualization\n",
    "            top_0_1_map = np.where(depth_heatmap >= threshold_0_1, depth_heatmap, depth_heatmap * 0)\n",
    "            top_0_05_map = np.where(depth_heatmap >= threshold_0_05, depth_heatmap, depth_heatmap * 0)\n",
    "\n",
    "            depth_unique_values = np.unique(depth_heatmap)\n",
    "            depth_unique_values = np.sort(depth_unique_values)[::-1]  # Descending order\n",
    "\n",
    "            # Select top 4 unique values\n",
    "            depth_top_values = depth_unique_values[:4]  # Take top 4 values\n",
    "            # print(f\"top values semantic is: {top_values}\")\n",
    "            # Apply filters to include cumulative top values\n",
    "            depth_top_1_value = np.where(depth_heatmap == depth_top_values[0], depth_heatmap, 0) if len(depth_top_values) > 0 else np.zeros_like(depth_heatmap)\n",
    "            depth_top_2_value = np.where(np.isin(depth_heatmap, depth_top_values[:2]), depth_heatmap, 0) if len(depth_top_values) > 1 else np.zeros_like(depth_heatmap)\n",
    "            \n",
    "            # Append all maps and sampled indices\n",
    "            heatmaps.append((file_name,depth_prob_vol, depth_heatmap, top_0_1_map, top_0_05_map))\n",
    "\n",
    "    # Sort heatmaps by camera number\n",
    "    heatmaps.sort(key=lambda x: extract_camera_number(x[0]))\n",
    "\n",
    "    # Limit to the specified number of cameras\n",
    "    heatmaps = heatmaps[:num_cameras]\n",
    "\n",
    "    # Adjust the number of rows in the figure\n",
    "    fig, axes = plt.subplots(len(heatmaps) * 2, 6, figsize=(24, len(heatmaps) * 12))\n",
    "\n",
    "    for i, (file_name, depth_prob_vol, depth_heatmap, top_0_1_map, top_0_05_map) in enumerate(heatmaps):\n",
    "        true_pose = poses[i] if i < len(poses) else None  # Match pose to the heatmap if available\n",
    "\n",
    "        # Semantic file corresponding to the depth file\n",
    "        semantic_file_name = file_name.replace(\"pred_depth_prob_vol.pt.gz\", \"pred_semantic_prob_vol.pt.gz\")\n",
    "        semantic_file_path = os.path.join(scene_dir, semantic_file_name)\n",
    "\n",
    "        if os.path.exists(semantic_file_path):\n",
    "            # Load semantic tensor\n",
    "            semantic_prob_vol = load_compressed_tensor(semantic_file_path)\n",
    "            semantic_heatmap = semantic_prob_vol.max(dim=2).values.numpy()\n",
    "\n",
    "            unique_values = np.unique(semantic_heatmap)\n",
    "            unique_values = np.sort(unique_values)[::-1]  # Descending order\n",
    "\n",
    "            # Select top 4 unique values\n",
    "            top_values = unique_values  # Take top 4 values\n",
    "            # print(f\"top values semantic is: {top_values}\")\n",
    "            # Apply filters to include cumulative top values\n",
    "            semantic_top_1_value = np.where(semantic_heatmap == top_values[0], semantic_heatmap, 0) if len(top_values) > 0 else np.zeros_like(semantic_heatmap)\n",
    "            semantic_top_2_value = np.where(np.isin(semantic_heatmap, top_values[:100]), semantic_heatmap, 0) if len(top_values) > 1 else np.zeros_like(semantic_heatmap)\n",
    "\n",
    "            # Combine depth and semantic heatmaps\n",
    "            combined_heatmap_after_max = 0.5 * semantic_heatmap + 0.5 * depth_heatmap\n",
    "            combined_heatmap_before_max = 0.5 * depth_prob_vol + 0.5 * semantic_prob_vol\n",
    "            combined_heatmap_before_max = combined_heatmap_before_max.max(dim=2).values.numpy()\n",
    "            combined_threshold_0_1 = np.percentile(combined_heatmap_before_max, 99.9)\n",
    "            combined_threshold_0_05 = np.percentile(combined_heatmap_before_max, 99.95)\n",
    "            combined_after_threshold_0_1 = np.percentile(combined_heatmap_after_max, 99.9)\n",
    "            combined_after_threshold_0_05 = np.percentile(combined_heatmap_after_max, 99.95)\n",
    "\n",
    "            combined_top_0_1_map = np.where(combined_heatmap_before_max >= combined_threshold_0_1, combined_heatmap_before_max, 0)\n",
    "            combined_top_0_05_map = np.where(combined_heatmap_before_max >= combined_threshold_0_05, combined_heatmap_before_max, 0)\n",
    "            combined_after_top_0_1_map = np.where(combined_heatmap_after_max >= combined_after_threshold_0_1, combined_heatmap_after_max, 0)\n",
    "            combined_after_top_0_05_map = np.where(combined_heatmap_after_max >= combined_after_threshold_0_05, combined_heatmap_after_max, 0)\n",
    "            \n",
    "            unique_values_combined = np.unique(combined_heatmap_before_max)\n",
    "            unique_values_combined = np.sort(unique_values_combined)[::-1]  # Descending order\n",
    "\n",
    "            # Select top 4 unique values\n",
    "            top_values_combined = unique_values_combined[:4]  # Take top 4 values\n",
    "\n",
    "            # Apply filters to include cumulative top values\n",
    "            combined_top_1_value = np.where(combined_heatmap_before_max == top_values_combined[0], combined_heatmap_before_max, 0) if len(top_values) > 0 else np.zeros_like(combined_heatmap_before_max)\n",
    "            combined_top_2_value = np.where(np.isin(combined_heatmap_before_max, top_values_combined[:2]), combined_heatmap_before_max, 0) if len(top_values) > 1 else np.zeros_like(combined_heatmap_before_max)\n",
    "            \n",
    "        else:\n",
    "            semantic_heatmap = None\n",
    "            semantic_top_0_1_map = semantic_top_0_05_map = None\n",
    "            combined_top_0_1_map = combined_top_0_05_map = None\n",
    "\n",
    "        # Plot original and thresholds for depth and semantic heatmaps\n",
    "        plot_single_map(depth_heatmap, None, true_pose, depth_heatmap.shape[0], depth_heatmap.shape[1], 0.1, f\"Original Depth: {file_name}\", axes[i * 2, 0])\n",
    "        plot_single_map(top_0_1_map, None, true_pose, depth_heatmap.shape[0], depth_heatmap.shape[1], 0.1, f\"top 0.1%: {file_name}\", axes[i * 2, 1])\n",
    "        plot_single_map(top_0_05_map, None, true_pose, depth_heatmap.shape[0], depth_heatmap.shape[1], 0.1, f\"top 1%: {file_name}\", axes[i * 2, 2])\n",
    "        plot_single_map(combined_heatmap_before_max, None, true_pose, combined_heatmap_before_max.shape[0], combined_heatmap_before_max.shape[1], 0.1, f\"combined_heatmap_before_max\", axes[i * 2 , 3])\n",
    "        plot_single_map(combined_top_0_1_map, None, true_pose, combined_heatmap_before_max.shape[0], combined_heatmap_before_max.shape[1], 0.1, f\"Combined 0.1%\", axes[i * 2 , 4])\n",
    "        plot_single_map(combined_top_0_05_map, None, true_pose, combined_heatmap_before_max.shape[0], combined_heatmap_before_max.shape[1], 0.1, f\"Combined 0.05%\", axes[i * 2 , 5])\n",
    "\n",
    "        if semantic_heatmap is not None:\n",
    "            plot_single_map(semantic_heatmap, None, true_pose, semantic_heatmap.shape[0], semantic_heatmap.shape[1], 0.1, f\"Original Semantic: {semantic_file_name}\", axes[i * 2 +1, 0])\n",
    "            plot_single_map(semantic_top_2_value, None, true_pose, semantic_heatmap.shape[0], semantic_heatmap.shape[1], 0.1, f\"Top 2 Semantic: {semantic_file_name}\", axes[i * 2 + 1, 1])\n",
    "            plot_single_map(semantic_top_1_value, None, true_pose, semantic_heatmap.shape[0], semantic_heatmap.shape[1], 0.1, f\"Top 1 Semantic: {semantic_file_name}\", axes[i * 2 + 1, 2])\n",
    "            plot_single_map(combined_heatmap_after_max, None, true_pose, semantic_heatmap.shape[0], semantic_heatmap.shape[1], 0.1, f\"combined_heatmap_after_max\", axes[i * 2 + 1, 3])\n",
    "            plot_single_map(combined_after_top_0_1_map, None, true_pose, combined_after_top_0_1_map.shape[0], combined_after_top_0_1_map.shape[1], 0.1, f\"Combined 0.1%\", axes[i * 2 +1 , 4])\n",
    "            plot_single_map(combined_after_top_0_05_map, None, true_pose, combined_after_top_0_05_map.shape[0], combined_after_top_0_05_map.shape[1], 0.1, f\"Combined 0.05%\", axes[i * 2 +1 , 5])\n",
    "            \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with example usage\n",
    "scene_num = 0\n",
    "scene_dir = f\"/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/test_data_set_full/prob_vols/scene_{scene_num}\"\n",
    "poses_file = f\"/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/test_data_set_full/structured3d_perspective_full/scene_{scene_num}/poses.txt\"\n",
    "\n",
    "poses = read_poses(poses_file)\n",
    "num_cameras = 20  # Number of cameras to process\n",
    "plot_camera_heatmaps_with_combination(scene_dir, poses, num_cameras=num_cameras)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
