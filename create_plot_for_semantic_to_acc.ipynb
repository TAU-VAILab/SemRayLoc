{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mascher/anaconda3/envs/yuval_fp/lib/python3.8/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/home/mascher/anaconda3/envs/yuval_fp/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mascher/anaconda3/envs/yuval_fp/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  2%|▏         | 5/249 [00:00<00:05, 47.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 1 out of: 249 --> 0.4016064257028112%\n",
      "number of valid scenes for evaluation: 2 out of: 249 --> 0.8032128514056224%\n",
      "number of valid scenes for evaluation: 3 out of: 249 --> 1.2048192771084338%\n",
      "number of valid scenes for evaluation: 4 out of: 249 --> 1.6064257028112447%\n",
      "number of valid scenes for evaluation: 5 out of: 249 --> 2.0080321285140563%\n",
      "number of valid scenes for evaluation: 6 out of: 249 --> 2.4096385542168677%\n",
      "number of valid scenes for evaluation: 7 out of: 249 --> 2.8112449799196786%\n",
      "number of valid scenes for evaluation: 8 out of: 249 --> 3.2128514056224895%\n",
      "number of valid scenes for evaluation: 9 out of: 249 --> 3.614457831325301%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10/249 [00:00<00:05, 41.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 10 out of: 249 --> 4.016064257028113%\n",
      "number of valid scenes for evaluation: 11 out of: 249 --> 4.417670682730924%\n",
      "number of valid scenes for evaluation: 12 out of: 249 --> 4.819277108433735%\n",
      "number of valid scenes for evaluation: 13 out of: 249 --> 5.220883534136546%\n",
      "number of valid scenes for evaluation: 14 out of: 249 --> 5.622489959839357%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 23/249 [00:00<00:05, 43.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 15 out of: 249 --> 6.024096385542169%\n",
      "number of valid scenes for evaluation: 16 out of: 249 --> 6.425702811244979%\n",
      "number of valid scenes for evaluation: 17 out of: 249 --> 6.827309236947792%\n",
      "number of valid scenes for evaluation: 18 out of: 249 --> 7.228915662650602%\n",
      "number of valid scenes for evaluation: 19 out of: 249 --> 7.630522088353414%\n",
      "number of valid scenes for evaluation: 20 out of: 249 --> 8.032128514056225%\n",
      "number of valid scenes for evaluation: 21 out of: 249 --> 8.433734939759036%\n",
      "number of valid scenes for evaluation: 22 out of: 249 --> 8.835341365461847%\n",
      "number of valid scenes for evaluation: 23 out of: 249 --> 9.236947791164658%\n",
      "number of valid scenes for evaluation: 24 out of: 249 --> 9.63855421686747%\n",
      "number of valid scenes for evaluation: 25 out of: 249 --> 10.040160642570282%\n",
      "number of valid scenes for evaluation: 26 out of: 249 --> 10.441767068273093%\n",
      "number of valid scenes for evaluation: 27 out of: 249 --> 10.843373493975903%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 35/249 [00:00<00:04, 45.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 28 out of: 249 --> 11.244979919678714%\n",
      "number of valid scenes for evaluation: 29 out of: 249 --> 11.646586345381527%\n",
      "number of valid scenes for evaluation: 30 out of: 249 --> 12.048192771084338%\n",
      "number of valid scenes for evaluation: 31 out of: 249 --> 12.449799196787147%\n",
      "number of valid scenes for evaluation: 32 out of: 249 --> 12.851405622489958%\n",
      "number of valid scenes for evaluation: 33 out of: 249 --> 13.253012048192772%\n",
      "number of valid scenes for evaluation: 34 out of: 249 --> 13.654618473895583%\n",
      "number of valid scenes for evaluation: 35 out of: 249 --> 14.056224899598394%\n",
      "number of valid scenes for evaluation: 36 out of: 249 --> 14.457831325301203%\n",
      "number of valid scenes for evaluation: 37 out of: 249 --> 14.859437751004014%\n",
      "number of valid scenes for evaluation: 38 out of: 249 --> 15.261044176706829%\n",
      "number of valid scenes for evaluation: 39 out of: 249 --> 15.66265060240964%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 49/249 [00:01<00:03, 53.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 40 out of: 249 --> 16.06425702811245%\n",
      "number of valid scenes for evaluation: 41 out of: 249 --> 16.46586345381526%\n",
      "number of valid scenes for evaluation: 42 out of: 249 --> 16.867469879518072%\n",
      "number of valid scenes for evaluation: 43 out of: 249 --> 17.269076305220885%\n",
      "number of valid scenes for evaluation: 44 out of: 249 --> 17.670682730923694%\n",
      "number of valid scenes for evaluation: 45 out of: 249 --> 18.072289156626507%\n",
      "number of valid scenes for evaluation: 46 out of: 249 --> 18.473895582329316%\n",
      "number of valid scenes for evaluation: 47 out of: 249 --> 18.87550200803213%\n",
      "number of valid scenes for evaluation: 48 out of: 249 --> 19.27710843373494%\n",
      "number of valid scenes for evaluation: 49 out of: 249 --> 19.67871485943775%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 55/249 [00:01<00:03, 51.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 50 out of: 249 --> 20.080321285140563%\n",
      "number of valid scenes for evaluation: 51 out of: 249 --> 20.481927710843372%\n",
      "number of valid scenes for evaluation: 52 out of: 249 --> 20.883534136546185%\n",
      "number of valid scenes for evaluation: 53 out of: 249 --> 21.285140562248998%\n",
      "number of valid scenes for evaluation: 54 out of: 249 --> 21.686746987951807%\n",
      "number of valid scenes for evaluation: 55 out of: 249 --> 22.08835341365462%\n",
      "number of valid scenes for evaluation: 56 out of: 249 --> 22.48995983935743%\n",
      "number of valid scenes for evaluation: 57 out of: 249 --> 22.89156626506024%\n",
      "number of valid scenes for evaluation: 58 out of: 249 --> 23.293172690763054%\n",
      "number of valid scenes for evaluation: 59 out of: 249 --> 23.694779116465863%\n",
      "number of valid scenes for evaluation: 60 out of: 249 --> 24.096385542168676%\n",
      "number of valid scenes for evaluation: 61 out of: 249 --> 24.497991967871485%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 70/249 [00:01<00:03, 57.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 62 out of: 249 --> 24.899598393574294%\n",
      "number of valid scenes for evaluation: 63 out of: 249 --> 25.301204819277107%\n",
      "number of valid scenes for evaluation: 64 out of: 249 --> 25.702811244979916%\n",
      "number of valid scenes for evaluation: 65 out of: 249 --> 26.104417670682732%\n",
      "number of valid scenes for evaluation: 66 out of: 249 --> 26.506024096385545%\n",
      "number of valid scenes for evaluation: 67 out of: 249 --> 26.907630522088354%\n",
      "number of valid scenes for evaluation: 68 out of: 249 --> 27.309236947791167%\n",
      "number of valid scenes for evaluation: 69 out of: 249 --> 27.710843373493976%\n",
      "number of valid scenes for evaluation: 70 out of: 249 --> 28.11244979919679%\n",
      "number of valid scenes for evaluation: 71 out of: 249 --> 28.514056224899598%\n",
      "number of valid scenes for evaluation: 72 out of: 249 --> 28.915662650602407%\n",
      "number of valid scenes for evaluation: 73 out of: 249 --> 29.31726907630522%\n",
      "number of valid scenes for evaluation: 74 out of: 249 --> 29.71887550200803%\n",
      "number of valid scenes for evaluation: 75 out of: 249 --> 30.120481927710845%\n",
      "number of valid scenes for evaluation: 76 out of: 249 --> 30.522088353413658%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 85/249 [00:01<00:02, 62.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 77 out of: 249 --> 30.923694779116467%\n",
      "number of valid scenes for evaluation: 78 out of: 249 --> 31.32530120481928%\n",
      "number of valid scenes for evaluation: 79 out of: 249 --> 31.72690763052209%\n",
      "number of valid scenes for evaluation: 80 out of: 249 --> 32.1285140562249%\n",
      "number of valid scenes for evaluation: 81 out of: 249 --> 32.53012048192771%\n",
      "number of valid scenes for evaluation: 82 out of: 249 --> 32.93172690763052%\n",
      "number of valid scenes for evaluation: 83 out of: 249 --> 33.33333333333333%\n",
      "number of valid scenes for evaluation: 84 out of: 249 --> 33.734939759036145%\n",
      "number of valid scenes for evaluation: 85 out of: 249 --> 34.13654618473896%\n",
      "number of valid scenes for evaluation: 86 out of: 249 --> 34.53815261044177%\n",
      "number of valid scenes for evaluation: 87 out of: 249 --> 34.93975903614458%\n",
      "number of valid scenes for evaluation: 88 out of: 249 --> 35.34136546184739%\n",
      "number of valid scenes for evaluation: 89 out of: 249 --> 35.7429718875502%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 100/249 [00:01<00:02, 63.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 90 out of: 249 --> 36.144578313253014%\n",
      "number of valid scenes for evaluation: 91 out of: 249 --> 36.54618473895582%\n",
      "number of valid scenes for evaluation: 92 out of: 249 --> 36.94779116465863%\n",
      "number of valid scenes for evaluation: 93 out of: 249 --> 37.34939759036144%\n",
      "number of valid scenes for evaluation: 94 out of: 249 --> 37.75100401606426%\n",
      "number of valid scenes for evaluation: 95 out of: 249 --> 38.152610441767074%\n",
      "number of valid scenes for evaluation: 96 out of: 249 --> 38.55421686746988%\n",
      "number of valid scenes for evaluation: 97 out of: 249 --> 38.95582329317269%\n",
      "number of valid scenes for evaluation: 98 out of: 249 --> 39.3574297188755%\n",
      "number of valid scenes for evaluation: 99 out of: 249 --> 39.75903614457831%\n",
      "number of valid scenes for evaluation: 100 out of: 249 --> 40.16064257028113%\n",
      "number of valid scenes for evaluation: 101 out of: 249 --> 40.562248995983936%\n",
      "number of valid scenes for evaluation: 102 out of: 249 --> 40.963855421686745%\n",
      "number of valid scenes for evaluation: 103 out of: 249 --> 41.365461847389554%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 114/249 [00:02<00:02, 59.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 104 out of: 249 --> 41.76706827309237%\n",
      "number of valid scenes for evaluation: 105 out of: 249 --> 42.168674698795186%\n",
      "number of valid scenes for evaluation: 106 out of: 249 --> 42.570281124497996%\n",
      "number of valid scenes for evaluation: 107 out of: 249 --> 42.971887550200805%\n",
      "number of valid scenes for evaluation: 108 out of: 249 --> 43.373493975903614%\n",
      "number of valid scenes for evaluation: 109 out of: 249 --> 43.77510040160642%\n",
      "number of valid scenes for evaluation: 110 out of: 249 --> 44.17670682730924%\n",
      "number of valid scenes for evaluation: 111 out of: 249 --> 44.57831325301205%\n",
      "number of valid scenes for evaluation: 112 out of: 249 --> 44.97991967871486%\n",
      "number of valid scenes for evaluation: 113 out of: 249 --> 45.38152610441767%\n",
      "number of valid scenes for evaluation: 114 out of: 249 --> 45.78313253012048%\n",
      "number of valid scenes for evaluation: 115 out of: 249 --> 46.1847389558233%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 129/249 [00:02<00:01, 65.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 116 out of: 249 --> 46.58634538152611%\n",
      "number of valid scenes for evaluation: 117 out of: 249 --> 46.98795180722892%\n",
      "number of valid scenes for evaluation: 118 out of: 249 --> 47.389558232931726%\n",
      "number of valid scenes for evaluation: 119 out of: 249 --> 47.791164658634536%\n",
      "number of valid scenes for evaluation: 120 out of: 249 --> 48.19277108433735%\n",
      "number of valid scenes for evaluation: 121 out of: 249 --> 48.59437751004016%\n",
      "number of valid scenes for evaluation: 122 out of: 249 --> 48.99598393574297%\n",
      "number of valid scenes for evaluation: 123 out of: 249 --> 49.39759036144578%\n",
      "number of valid scenes for evaluation: 124 out of: 249 --> 49.79919678714859%\n",
      "number of valid scenes for evaluation: 125 out of: 249 --> 50.20080321285141%\n",
      "number of valid scenes for evaluation: 126 out of: 249 --> 50.602409638554214%\n",
      "number of valid scenes for evaluation: 127 out of: 249 --> 51.00401606425703%\n",
      "number of valid scenes for evaluation: 128 out of: 249 --> 51.40562248995983%\n",
      "number of valid scenes for evaluation: 129 out of: 249 --> 51.80722891566265%\n",
      "number of valid scenes for evaluation: 130 out of: 249 --> 52.208835341365464%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 136/249 [00:02<00:01, 63.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 131 out of: 249 --> 52.610441767068274%\n",
      "number of valid scenes for evaluation: 132 out of: 249 --> 53.01204819277109%\n",
      "number of valid scenes for evaluation: 133 out of: 249 --> 53.41365461847389%\n",
      "number of valid scenes for evaluation: 134 out of: 249 --> 53.81526104417671%\n",
      "number of valid scenes for evaluation: 135 out of: 249 --> 54.21686746987952%\n",
      "number of valid scenes for evaluation: 136 out of: 249 --> 54.61847389558233%\n",
      "number of valid scenes for evaluation: 137 out of: 249 --> 55.020080321285135%\n",
      "number of valid scenes for evaluation: 138 out of: 249 --> 55.42168674698795%\n",
      "number of valid scenes for evaluation: 139 out of: 249 --> 55.82329317269076%\n",
      "number of valid scenes for evaluation: 140 out of: 249 --> 56.22489959839358%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 149/249 [00:02<00:01, 55.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 141 out of: 249 --> 56.62650602409639%\n",
      "number of valid scenes for evaluation: 142 out of: 249 --> 57.028112449799195%\n",
      "number of valid scenes for evaluation: 143 out of: 249 --> 57.42971887550201%\n",
      "number of valid scenes for evaluation: 144 out of: 249 --> 57.831325301204814%\n",
      "number of valid scenes for evaluation: 145 out of: 249 --> 58.23293172690763%\n",
      "number of valid scenes for evaluation: 146 out of: 249 --> 58.63453815261044%\n",
      "number of valid scenes for evaluation: 147 out of: 249 --> 59.036144578313255%\n",
      "number of valid scenes for evaluation: 148 out of: 249 --> 59.43775100401606%\n",
      "number of valid scenes for evaluation: 149 out of: 249 --> 59.83935742971887%\n",
      "number of valid scenes for evaluation: 150 out of: 249 --> 60.24096385542169%\n",
      "number of valid scenes for evaluation: 151 out of: 249 --> 60.6425702811245%\n",
      "number of valid scenes for evaluation: 152 out of: 249 --> 61.044176706827315%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 162/249 [00:02<00:01, 58.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 153 out of: 249 --> 61.44578313253012%\n",
      "number of valid scenes for evaluation: 154 out of: 249 --> 61.84738955823293%\n",
      "number of valid scenes for evaluation: 155 out of: 249 --> 62.24899598393574%\n",
      "number of valid scenes for evaluation: 156 out of: 249 --> 62.65060240963856%\n",
      "number of valid scenes for evaluation: 157 out of: 249 --> 63.05220883534136%\n",
      "number of valid scenes for evaluation: 158 out of: 249 --> 63.45381526104418%\n",
      "number of valid scenes for evaluation: 159 out of: 249 --> 63.85542168674698%\n",
      "number of valid scenes for evaluation: 160 out of: 249 --> 64.2570281124498%\n",
      "number of valid scenes for evaluation: 161 out of: 249 --> 64.65863453815261%\n",
      "number of valid scenes for evaluation: 162 out of: 249 --> 65.06024096385542%\n",
      "number of valid scenes for evaluation: 163 out of: 249 --> 65.46184738955823%\n",
      "number of valid scenes for evaluation: 164 out of: 249 --> 65.86345381526104%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 175/249 [00:03<00:01, 60.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 165 out of: 249 --> 66.26506024096386%\n",
      "number of valid scenes for evaluation: 166 out of: 249 --> 66.66666666666666%\n",
      "number of valid scenes for evaluation: 167 out of: 249 --> 67.06827309236948%\n",
      "number of valid scenes for evaluation: 168 out of: 249 --> 67.46987951807229%\n",
      "number of valid scenes for evaluation: 169 out of: 249 --> 67.8714859437751%\n",
      "number of valid scenes for evaluation: 170 out of: 249 --> 68.27309236947792%\n",
      "number of valid scenes for evaluation: 171 out of: 249 --> 68.67469879518072%\n",
      "number of valid scenes for evaluation: 172 out of: 249 --> 69.07630522088354%\n",
      "number of valid scenes for evaluation: 173 out of: 249 --> 69.47791164658635%\n",
      "number of valid scenes for evaluation: 174 out of: 249 --> 69.87951807228916%\n",
      "number of valid scenes for evaluation: 175 out of: 249 --> 70.28112449799197%\n",
      "number of valid scenes for evaluation: 176 out of: 249 --> 70.68273092369478%\n",
      "number of valid scenes for evaluation: 177 out of: 249 --> 71.08433734939759%\n",
      "number of valid scenes for evaluation: 178 out of: 249 --> 71.4859437751004%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 189/249 [00:03<00:00, 62.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 179 out of: 249 --> 71.8875502008032%\n",
      "number of valid scenes for evaluation: 180 out of: 249 --> 72.28915662650603%\n",
      "number of valid scenes for evaluation: 181 out of: 249 --> 72.69076305220884%\n",
      "number of valid scenes for evaluation: 182 out of: 249 --> 73.09236947791165%\n",
      "number of valid scenes for evaluation: 183 out of: 249 --> 73.49397590361446%\n",
      "number of valid scenes for evaluation: 184 out of: 249 --> 73.89558232931726%\n",
      "number of valid scenes for evaluation: 185 out of: 249 --> 74.29718875502009%\n",
      "number of valid scenes for evaluation: 186 out of: 249 --> 74.69879518072288%\n",
      "number of valid scenes for evaluation: 187 out of: 249 --> 75.1004016064257%\n",
      "number of valid scenes for evaluation: 188 out of: 249 --> 75.50200803212851%\n",
      "number of valid scenes for evaluation: 189 out of: 249 --> 75.90361445783132%\n",
      "number of valid scenes for evaluation: 190 out of: 249 --> 76.30522088353415%\n",
      "number of valid scenes for evaluation: 191 out of: 249 --> 76.70682730923694%\n",
      "number of valid scenes for evaluation: 192 out of: 249 --> 77.10843373493977%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 203/249 [00:03<00:00, 60.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 193 out of: 249 --> 77.51004016064257%\n",
      "number of valid scenes for evaluation: 194 out of: 249 --> 77.91164658634538%\n",
      "number of valid scenes for evaluation: 195 out of: 249 --> 78.3132530120482%\n",
      "number of valid scenes for evaluation: 196 out of: 249 --> 78.714859437751%\n",
      "number of valid scenes for evaluation: 197 out of: 249 --> 79.11646586345381%\n",
      "number of valid scenes for evaluation: 198 out of: 249 --> 79.51807228915662%\n",
      "number of valid scenes for evaluation: 199 out of: 249 --> 79.91967871485943%\n",
      "number of valid scenes for evaluation: 200 out of: 249 --> 80.32128514056225%\n",
      "number of valid scenes for evaluation: 201 out of: 249 --> 80.72289156626506%\n",
      "number of valid scenes for evaluation: 202 out of: 249 --> 81.12449799196787%\n",
      "number of valid scenes for evaluation: 203 out of: 249 --> 81.52610441767068%\n",
      "number of valid scenes for evaluation: 204 out of: 249 --> 81.92771084337349%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 217/249 [00:03<00:00, 61.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 205 out of: 249 --> 82.32931726907631%\n",
      "number of valid scenes for evaluation: 206 out of: 249 --> 82.73092369477911%\n",
      "number of valid scenes for evaluation: 207 out of: 249 --> 83.13253012048193%\n",
      "number of valid scenes for evaluation: 208 out of: 249 --> 83.53413654618474%\n",
      "number of valid scenes for evaluation: 209 out of: 249 --> 83.93574297188755%\n",
      "number of valid scenes for evaluation: 210 out of: 249 --> 84.33734939759037%\n",
      "number of valid scenes for evaluation: 211 out of: 249 --> 84.73895582329317%\n",
      "number of valid scenes for evaluation: 212 out of: 249 --> 85.14056224899599%\n",
      "number of valid scenes for evaluation: 213 out of: 249 --> 85.54216867469879%\n",
      "number of valid scenes for evaluation: 214 out of: 249 --> 85.94377510040161%\n",
      "number of valid scenes for evaluation: 215 out of: 249 --> 86.34538152610442%\n",
      "number of valid scenes for evaluation: 216 out of: 249 --> 86.74698795180723%\n",
      "number of valid scenes for evaluation: 217 out of: 249 --> 87.14859437751004%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 224/249 [00:03<00:00, 58.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 218 out of: 249 --> 87.55020080321285%\n",
      "number of valid scenes for evaluation: 219 out of: 249 --> 87.95180722891565%\n",
      "number of valid scenes for evaluation: 220 out of: 249 --> 88.35341365461848%\n",
      "number of valid scenes for evaluation: 221 out of: 249 --> 88.75502008032129%\n",
      "number of valid scenes for evaluation: 222 out of: 249 --> 89.1566265060241%\n",
      "number of valid scenes for evaluation: 223 out of: 249 --> 89.5582329317269%\n",
      "number of valid scenes for evaluation: 224 out of: 249 --> 89.95983935742971%\n",
      "number of valid scenes for evaluation: 225 out of: 249 --> 90.36144578313254%\n",
      "number of valid scenes for evaluation: 226 out of: 249 --> 90.76305220883533%\n",
      "number of valid scenes for evaluation: 227 out of: 249 --> 91.16465863453816%\n",
      "number of valid scenes for evaluation: 228 out of: 249 --> 91.56626506024097%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 236/249 [00:04<00:00, 55.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 229 out of: 249 --> 91.96787148594377%\n",
      "number of valid scenes for evaluation: 230 out of: 249 --> 92.3694779116466%\n",
      "number of valid scenes for evaluation: 231 out of: 249 --> 92.7710843373494%\n",
      "number of valid scenes for evaluation: 232 out of: 249 --> 93.17269076305222%\n",
      "number of valid scenes for evaluation: 233 out of: 249 --> 93.57429718875501%\n",
      "number of valid scenes for evaluation: 234 out of: 249 --> 93.97590361445783%\n",
      "number of valid scenes for evaluation: 235 out of: 249 --> 94.37751004016064%\n",
      "number of valid scenes for evaluation: 236 out of: 249 --> 94.77911646586345%\n",
      "number of valid scenes for evaluation: 237 out of: 249 --> 95.18072289156626%\n",
      "number of valid scenes for evaluation: 238 out of: 249 --> 95.58232931726907%\n",
      "number of valid scenes for evaluation: 239 out of: 249 --> 95.98393574297188%\n",
      "number of valid scenes for evaluation: 240 out of: 249 --> 96.3855421686747%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:04<00:00, 56.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid scenes for evaluation: 241 out of: 249 --> 96.78714859437751%\n",
      "number of valid scenes for evaluation: 242 out of: 249 --> 97.18875502008032%\n",
      "number of valid scenes for evaluation: 243 out of: 249 --> 97.59036144578313%\n",
      "number of valid scenes for evaluation: 244 out of: 249 --> 97.99196787148594%\n",
      "number of valid scenes for evaluation: 245 out of: 249 --> 98.39357429718876%\n",
      "number of valid scenes for evaluation: 246 out of: 249 --> 98.79518072289156%\n",
      "number of valid scenes for evaluation: 247 out of: 249 --> 99.19678714859438%\n",
      "number of valid scenes for evaluation: 248 out of: 249 --> 99.59839357429718%\n",
      "number of valid scenes for evaluation: 249 out of: 249 --> 100.0%\n",
      "Loading existing count data from /datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/results/final_results/visualtizations/semantic_vs_acc/count_dict_for_all_weights.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "import yaml\n",
    "from attrdict import AttrDict\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from modules.mono.depth_net_pl import depth_net_pl\n",
    "from modules.semantic.semantic_net_pl import semantic_net_pl\n",
    "from modules.semantic.semantic_net_pl_maskformer_small import semantic_net_pl_maskformer_smallpl\n",
    "from modules.semantic.semantic_mapper import ObjectType\n",
    "from data_utils.data_utils import GridSeqDataset\n",
    "from data_utils.prob_vol_data_utils import ProbVolDataset\n",
    "from utils.localization_utils import (\n",
    "    get_ray_from_depth, get_ray_from_semantics_v2, localize, finalize_localization\n",
    ")\n",
    "from utils.data_loader_helper import load_scene_datad\n",
    "from utils.visualization_utils import plot_dict_relationship\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Hard-coded configuration\n",
    "config = AttrDict({\n",
    "    'dataset_dir': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/test_data_set_full/structured3d_perspective_full',\n",
    "    'desdf_path': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/test_data_set_full/desdf',\n",
    "    'log_dir_depth': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/modules/Final_wights/depth/final_depth_model_checkpoint.ckpt',\n",
    "    'log_dir_semantic': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/modules/Final_wights/semantic/final_semantic_model_checkpoint.ckpt',\n",
    "    'split_file': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/test_data_set_full/structured3d_perspective_full/split.yaml',\n",
    "    'prob_vol_path': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/test_data_set_full/prob_vols',\n",
    "    \n",
    "    'results_dir': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/results/full/GT',\n",
    "    'combined_prob_vols_net_path': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/logs/combined/expected_pose_pred/combined_prob_vols_net_type-expected_pose_pred_net_size-6k_dataset_size-medium_epochs-99/combined_net-epoch=58-loss-valid=7.16.ckpt',\n",
    "    'combined_net_size': '6k',\n",
    "    \n",
    "    'L': 0,\n",
    "    'D': 128,\n",
    "    'd_min': 0.1,\n",
    "    'd_max': 15.0,\n",
    "    'd_hyp': -0.2,\n",
    "    'F_W': 0.59587643422,\n",
    "    'V': 7,\n",
    "    'num_classes': 4,\n",
    "    'prediction_type': 'combined',\n",
    "    'use_ground_truth_depth': False,\n",
    "    'use_ground_truth_semantic': False,\n",
    "    'use_saved_prob_vol': False,\n",
    "    'num_of_scenes': 1,\n",
    "    'pad_to_max': True,\n",
    "    'max_h': 1760,\n",
    "    'max_w': 1760,\n",
    "    'weight_combinations': [\n",
    "        [1.0, 0.0],\n",
    "        # [0, 1.0],\n",
    "        [0.5, 0.5]\n",
    "    ],    \n",
    "    'use_semantic_mask2foremr': True,\n",
    "    'semantic_mask2former_path': '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/logs/mask2Former_semantics_with_tiny_small_version_no_augmentaion/semantic/semantic_net-epoch=19-loss-valid=0.34.ckpt'\n",
    "})\n",
    "\n",
    "def save_data(data, path):\n",
    "    \"\"\"Saves data to a specified path using pickle.\"\"\"\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Loads data from a specified path using pickle.\"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def pad_to_max(prob_vol, max_H, max_W):\n",
    "    return F.pad(prob_vol, (0, max_W - prob_vol.shape[1], 0, max_H - prob_vol.shape[0]))\n",
    "\n",
    "\n",
    "def plot_acc_vs_count(count_dict_for_all_weights, count_name, save_path, data_type):\n",
    "    \"\"\"\n",
    "    Plots accuracy vs number of objects for different weight combinations with smoothing and range shading.\n",
    "    :param count_dict_for_all_weights: Dictionary containing accuracy values for different weights.\n",
    "    :param count_name: Type of object (e.g., windows, doors, doors_and_walls).\n",
    "    :param save_path: Path to save the plot.\n",
    "    :param data_type: Data type ('pred' or 'gt').\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    for weight_key in count_dict_for_all_weights.keys():\n",
    "        sorted_counts = sorted(count_dict_for_all_weights[weight_key].keys())\n",
    "        mean_acc = [np.mean(count_dict_for_all_weights[weight_key][c]) for c in sorted_counts]\n",
    "        std_acc = [np.std(count_dict_for_all_weights[weight_key][c]) for c in sorted_counts]\n",
    "        \n",
    "        smoothed_mean = gaussian_filter1d(mean_acc, sigma=1)\n",
    "        \n",
    "        # Upper and lower bounds\n",
    "        lower_bound = np.maximum(np.array(mean_acc) - np.array(std_acc), 0)  # Ensure lower bound is >= 0\n",
    "        upper_bound = np.array(mean_acc) + np.array(std_acc)\n",
    "        # Plot the smoothed mean\n",
    "        sns.lineplot(x=sorted_counts, y=smoothed_mean, label=f'{weight_key}', linewidth=2)\n",
    "        sns.lineplot(x=sorted_counts, y=mean_acc, linewidth=1, alpha=0.4)\n",
    "        \n",
    "        # Add shaded range for bounds (unsmoothed)\n",
    "        # plt.fill_between(sorted_counts, lower_bound, upper_bound, alpha=0.05)\n",
    "\n",
    "    plt.xlabel(f'Number of {count_name} Rays')\n",
    "    plt.ylabel('Mean Accuracy (m)')\n",
    "    # plt.title(f'Mean Accuracy vs Number of {count_name} Rays ({data_type.upper()})')\n",
    "    plt.legend(title=\"Weight Combination\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, f'{data_type}_acc_vs_{count_name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_combined_model(\n",
    "    depth_net, semantic_net, desdfs, semantics, test_set, gt_poses, maps,\n",
    "    device, results_type_dir, valid_scene_names, config\n",
    "):\n",
    "    # Define file paths to save intermediate results\n",
    "    save_path = '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/results/final_results/mask2former/visualtizations/semantic_vs_acc'\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    counts_file = os.path.join(save_path, 'count_dict_for_all_weights.pkl')\n",
    "    \n",
    "    if os.path.exists(counts_file):\n",
    "        # Load existing data if it exists\n",
    "        print(f\"Loading existing count data from {counts_file}\")\n",
    "        data = load_data(counts_file)\n",
    "        windows_acc = data['windows_acc']\n",
    "        doors_acc = data['doors_acc']\n",
    "        doors_and_windows_acc = data['doors_and_windows_acc']\n",
    "        gt_windows_acc = data['gt_windows_acc']\n",
    "        gt_doors_acc = data['gt_doors_acc']\n",
    "        gt_doors_and_windows_acc = data['gt_doors_and_windows_acc']\n",
    "    else:\n",
    "        print(f\"No existing data found at {counts_file}, running calculations.\")\n",
    "        wc = config.weight_combinations\n",
    "        acc_records = {f\"{dw}_{sw}\": [] for dw, sw in wc}\n",
    "        acc_orn_records = {f\"{dw}_{sw}\": [] for dw, sw in wc}\n",
    "        all_weight_comb_dict = {f\"{dw}_{sw}\": {} for dw, sw in wc}\n",
    "        windows_acc = {f\"{dw}_{sw}\": defaultdict(list) for dw, sw in wc}\n",
    "        doors_acc = {f\"{dw}_{sw}\": defaultdict(list) for dw, sw in wc}\n",
    "        doors_and_windows_acc = {f\"{dw}_{sw}\": defaultdict(list) for dw, sw in wc}\n",
    "\n",
    "        # Dictionaries for GT data\n",
    "        gt_windows_acc = {f\"{dw}_{sw}\": defaultdict(list) for dw, sw in wc}\n",
    "        gt_doors_acc = {f\"{dw}_{sw}\": defaultdict(list) for dw, sw in wc}\n",
    "        gt_doors_and_windows_acc = {f\"{dw}_{sw}\": defaultdict(list) for dw, sw in wc}\n",
    "\n",
    "        for data_idx in tqdm.tqdm(range(len(test_set))):\n",
    "            data = test_set[data_idx]\n",
    "            scene_idx = np.sum(data_idx >= np.array(test_set.scene_start_idx)) - 1\n",
    "            scene = test_set.scene_names[scene_idx]\n",
    "            if 'floor' not in scene:\n",
    "                scene = f\"scene_{int(scene.split('_')[1])}\"\n",
    "            if scene not in valid_scene_names:\n",
    "                continue\n",
    "\n",
    "            idx_within_scene = data_idx - test_set.scene_start_idx[scene_idx]\n",
    "            desdf, semantic = desdfs[scene], semantics[scene]\n",
    "            ref_pose_map = gt_poses[scene][idx_within_scene * (config.L + 1) + config.L]\n",
    "\n",
    "            pred_depths = depth_net.encoder(torch.tensor(data[\"ref_img\"], device=device).unsqueeze(0), None)[0].squeeze(0).cpu().detach().numpy()\n",
    "            pred_rays_depth = get_ray_from_depth(pred_depths, V=config.V, F_W=config.F_W)\n",
    "            \n",
    "            gt_pred_depths = data[\"ref_depth\"]\n",
    "            gt_rays_depth = get_ray_from_depth(gt_pred_depths, V=config.V, F_W=config.F_W)\n",
    "\n",
    "            ref_img_t = torch.tensor(data[\"ref_img\"], device=device).unsqueeze(0)\n",
    "            _, _, prob = semantic_net.encoder(ref_img_t, None)\n",
    "            sampled_indices_np = torch.multinomial(prob.squeeze(0), 1, replacement=True).squeeze(1).cpu().detach().numpy()\n",
    "            pred_rays_semantic = get_ray_from_semantics_v2(sampled_indices_np)\n",
    "            \n",
    "            gt_sampled_indices_np = data[\"ref_semantics\"]\n",
    "            gt_rays_semantic = get_ray_from_semantics_v2(gt_sampled_indices_np)\n",
    "\n",
    "            prob_vol_pred_depth = localize(torch.tensor(desdf[\"desdf\"]), torch.tensor(pred_rays_depth), return_np=False)[0]\n",
    "            prob_vol_pred_semantic = localize(torch.tensor(semantic[\"desdf\"]), torch.tensor(pred_rays_semantic), return_np=False,localize_type=\"semantic\")[0]\n",
    "            \n",
    "            gt_prob_vol_pred_depth = localize(torch.tensor(desdf[\"desdf\"]), torch.tensor(gt_rays_depth), return_np=False)[0]\n",
    "            gt_prob_vol_pred_semantic = localize(torch.tensor(semantic[\"desdf\"]), torch.tensor(gt_rays_semantic), return_np=False,localize_type=\"semantic\")[0]\n",
    "\n",
    "            # Separate GT and semantic counts\n",
    "            num_windows_pred = np.sum(sampled_indices_np == ObjectType.WINDOW.value)\n",
    "            num_doors_pred = np.sum(sampled_indices_np == ObjectType.DOOR.value)\n",
    "            num_doors_and_windows_pred = np.sum((sampled_indices_np == ObjectType.DOOR.value) | (sampled_indices_np == ObjectType.WINDOW.value))\n",
    "\n",
    "            num_windows_gt = np.sum(gt_sampled_indices_np == ObjectType.WINDOW.value)\n",
    "            num_doors_gt = np.sum(gt_sampled_indices_np == ObjectType.DOOR.value)\n",
    "            num_doors_and_windows_gt = np.sum((gt_sampled_indices_np == ObjectType.DOOR.value) | (gt_sampled_indices_np == ObjectType.WINDOW.value))\n",
    "\n",
    "            for dw, sw in wc:\n",
    "                wkey = f\"{dw}_{sw}\"\n",
    "                min_shape = [min(d, s) for d, s in zip(prob_vol_pred_depth.shape, prob_vol_pred_semantic.shape)]\n",
    "                d_sliced = prob_vol_pred_depth[tuple(slice(0, m) for m in min_shape)]\n",
    "                s_sliced = prob_vol_pred_semantic[tuple(slice(0, m) for m in min_shape)]\n",
    "                combined_prob = dw * d_sliced + sw * s_sliced\n",
    "                _, pdp, _, pose_pred = finalize_localization(combined_prob)\n",
    "                pose_pred = torch.tensor(pose_pred, device=device, dtype=torch.float32)\n",
    "                pose_pred[:2] = pose_pred[:2] / 10\n",
    "                acc = torch.norm(pose_pred[:2] - torch.tensor(ref_pose_map[:2], device=device), 2).item()\n",
    "                acc_orn = ((pose_pred[2] - ref_pose_map[2]) % (2 * np.pi))\n",
    "                acc_orn = min(acc_orn, 2 * np.pi - acc_orn) / np.pi * 180\n",
    "                key = pdp.max().item()\n",
    "                all_weight_comb_dict[wkey].setdefault(key, []).append(acc)\n",
    "                acc_records[wkey].append(acc)\n",
    "                acc_orn_records[wkey].append(acc_orn)\n",
    "                windows_acc[wkey][num_windows_pred].append(acc)\n",
    "                doors_acc[wkey][num_doors_pred].append(acc)\n",
    "                doors_and_windows_acc[wkey][num_doors_and_windows_pred].append(acc)\n",
    "                \n",
    "                min_shape = [min(d, s) for d, s in zip(gt_prob_vol_pred_depth.shape, gt_prob_vol_pred_semantic.shape)]\n",
    "                d_gt_sliced = gt_prob_vol_pred_depth[tuple(slice(0, m) for m in min_shape)]\n",
    "                s_gt_sliced = gt_prob_vol_pred_semantic[tuple(slice(0, m) for m in min_shape)]\n",
    "                gt_combined_prob = dw * d_gt_sliced + sw * s_gt_sliced\n",
    "                _, gt_pdp, _, gt_pose_pred = finalize_localization(gt_combined_prob)\n",
    "                gt_pose_pred = torch.tensor(gt_pose_pred, device=device, dtype=torch.float32)\n",
    "                gt_pose_pred[:2] = gt_pose_pred[:2] / 10\n",
    "                gt_acc = torch.norm(gt_pose_pred[:2] - torch.tensor(ref_pose_map[:2], device=device), 2).item()\n",
    "                gt_windows_acc[wkey][num_windows_gt].append(gt_acc)\n",
    "                gt_doors_acc[wkey][num_doors_gt].append(gt_acc)\n",
    "                gt_doors_and_windows_acc[wkey][num_doors_and_windows_gt].append(gt_acc)\n",
    "                \n",
    "        # Save the computed results\n",
    "        data_to_save = {\n",
    "            'windows_acc': windows_acc,\n",
    "            'doors_acc': doors_acc,\n",
    "            'doors_and_windows_acc': doors_and_windows_acc,\n",
    "            'gt_windows_acc': gt_windows_acc,\n",
    "            'gt_doors_acc': gt_doors_acc,\n",
    "            'gt_doors_and_windows_acc': gt_doors_and_windows_acc\n",
    "        }\n",
    "        save_data(data_to_save, counts_file)\n",
    "\n",
    "\n",
    "    save_path = '/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/results/final_results/visualtizations/semantic_vs_acc'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    plot_acc_vs_count(windows_acc, 'windows', save_path, 'pred')\n",
    "    plot_acc_vs_count(doors_acc, 'doors', save_path, 'pred')\n",
    "    plot_acc_vs_count(doors_and_windows_acc, 'doors_and_windows', save_path, 'pred')\n",
    "    \n",
    "    plot_acc_vs_count(gt_windows_acc, 'windows', save_path, 'gt')\n",
    "    plot_acc_vs_count(gt_doors_acc, 'doors', save_path, 'gt')\n",
    "    plot_acc_vs_count(gt_doors_and_windows_acc, 'doors_and_windows', save_path, 'gt')\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_observation(prediction_type, config, device):\n",
    "    with open(config.split_file, \"r\") as f:\n",
    "        split = AttrDict(yaml.safe_load(f))\n",
    "    scene_names = split.test[:config.num_of_scenes] if config.num_of_scenes>0 else split.test\n",
    "    test_set = ProbVolDataset(config.dataset_dir, scene_names, L=config.L, prob_vol_path=config.prob_vol_path, acc_only=False) if config.use_saved_prob_vol \\\n",
    "               else GridSeqDataset(config.dataset_dir, scene_names, L=config.L)\n",
    "\n",
    "    depth_net, semantic_net = None, None\n",
    "    if not config.use_ground_truth_depth or not config.use_ground_truth_semantic:\n",
    "        if prediction_type in [\"depth\", \"combined\"]:\n",
    "            depth_net = depth_net_pl.load_from_checkpoint(config.log_dir_depth, d_min=config.d_min, d_max=config.d_max, d_hyp=config.d_hyp, D=config.D).to(device)\n",
    "        if prediction_type in [\"semantic\", \"combined\"]:\n",
    "            if config.use_semantic_mask2foremr:            \n",
    "                semantic_net = semantic_net_pl_maskformer_smallpl.load_from_checkpoint(config.semantic_mask2former_path, num_classes=config.num_classes).to(device)\n",
    "            else:\n",
    "                semantic_net = semantic_net_pl.load_from_checkpoint(config.log_dir_semantic, num_classes=config.num_classes).to(device)\n",
    "\n",
    "    results_type_dir = os.path.join(config.results_dir, prediction_type)\n",
    "    if config.use_ground_truth_depth or config.use_ground_truth_semantic:\n",
    "        results_type_dir = os.path.join(results_type_dir, \"gt\")\n",
    "    os.makedirs(results_type_dir, exist_ok=True)\n",
    "\n",
    "    desdfs, semantics, maps, gt_poses, valid_scene_names = load_scene_data(test_set, config.dataset_dir, config.desdf_path)\n",
    "    evaluate_combined_model(depth_net, semantic_net, desdfs, semantics, test_set, gt_poses, maps, device, results_type_dir, valid_scene_names, config)\n",
    "\n",
    "def main():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if config.prediction_type == \"all\":\n",
    "        for pt in [\"depth\", \"semantic\", \"combined\"]:\n",
    "            evaluate_observation(pt, config, device)\n",
    "    else:\n",
    "        evaluate_observation(config.prediction_type, config, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
