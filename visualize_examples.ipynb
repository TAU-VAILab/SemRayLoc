{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_415/2375241436.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensor = torch.load(f)\n",
      "/tmp/ipykernel_415/2375241436.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prob_vol = torch.tensor(prob_vol, device=device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import gzip\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "from utils.localization_utils import (\n",
    "    finalize_localization,\n",
    ")\n",
    "import shutil  # Import shutil for file copying\n",
    "\n",
    "def extract_camera_number(file_name):\n",
    "    match = re.search(r'\\d+', file_name)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return float('inf')\n",
    "\n",
    "def load_compressed_tensor(file_path):\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        tensor = torch.load(f)\n",
    "    return tensor\n",
    "\n",
    "def read_poses(file_path):\n",
    "    poses = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            x, y, orientation = map(float, line.strip().split())\n",
    "            poses.append((x, y, orientation))\n",
    "    return poses\n",
    "\n",
    "def plot_single_map(prob_vol, ref_pose_map, resolution, output_path, device='cpu'):\n",
    "    \"\"\"\n",
    "    Plots a heatmap using the original probability volume and calculates accuracy metrics.\n",
    "    \"\"\"\n",
    "    prob_vol = torch.tensor(prob_vol, device=device)\n",
    "    prob_vol_pred, prob_dist_pred, orientations_pred, pose_pred = finalize_localization(prob_vol)\n",
    "    \n",
    "    # Generate the probability map (2D projection of prob_vol)\n",
    "    prob_map = prob_dist_pred.astype(np.float32)  # Convert to NumPy array for visualization\n",
    "    prob_map = np.flipud(cv2.resize(prob_map, (prob_map.shape[1] * 10, prob_map.shape[0] * 10), interpolation=cv2.INTER_LINEAR))\n",
    "    H, W = prob_map.shape\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(prob_map, extent=[0, W, 0, H], cmap='jet', alpha=0.8, origin='lower')  # \"jet\" colormap\n",
    "\n",
    "    acc = acc_orn = 0  # Initialize metrics\n",
    "    if ref_pose_map is not None:\n",
    "        # Convert predicted pose to appropriate scale\n",
    "        pose_pred = torch.tensor(pose_pred, device=device, dtype=torch.float32)\n",
    "        pose_pred[:2] = pose_pred[:2] / 10  # Scale poses to match ground truth\n",
    "\n",
    "        # Calculate accuracy metrics\n",
    "        acc = torch.norm(pose_pred[:2] - torch.tensor(ref_pose_map[:2], device=device), p=2).item()\n",
    "        acc_orn = ((pose_pred[2] - torch.tensor(ref_pose_map[2], device=device)) % (2 * np.pi)).item()\n",
    "        acc_orn = min(acc_orn, 2 * np.pi - acc_orn) / np.pi * 180\n",
    "\n",
    "        # Plot Ground Truth (GT) pose as an arrow\n",
    "        gt_pose_x = ref_pose_map[0] * (1 / resolution) * 10\n",
    "        gt_pose_y = H - ref_pose_map[1] * (1 / resolution) * 10\n",
    "        gt_dx = np.cos(ref_pose_map[2]) * 30\n",
    "        gt_dy = np.sin(ref_pose_map[2]) * 30\n",
    "        # plt.arrow(\n",
    "        #     gt_pose_x, gt_pose_y, gt_dx, gt_dy,\n",
    "        #     width=30,head_width=80, head_length=60, fc='green', ec='black', alpha=1  \n",
    "        # )\n",
    "\n",
    "        # Plot predicted pose as an arrow\n",
    "        pred_pose_x = pose_pred[0].item() * (1 / resolution) * 10\n",
    "        pred_pose_y = H - pose_pred[1].item() * (1 / resolution) * 10\n",
    "        pred_dx = np.cos(pose_pred[2].item()) * 30\n",
    "        pred_dy = np.sin(pose_pred[2].item()) * 30\n",
    "        # plt.arrow(\n",
    "        #     pred_pose_x, pred_pose_y, pred_dx, pred_dy,\n",
    "        #     width=30,head_width=80, head_length=60, fc='white', ec='black', alpha=1 \n",
    "        # )\n",
    "\n",
    "    # Save the plot without additional headers\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    return acc, acc_orn  # Return accuracy metrics\n",
    "\n",
    "\n",
    "\n",
    "def create_scale_bar(save_dir, example_heatmap):\n",
    "    \"\"\"\n",
    "    Creates a probability scale bar image without numeric scale, only 'Low' and 'High' outside the bar.\n",
    "    \"\"\"\n",
    "    scale_bar_path = os.path.join(save_dir, \"scale_bar.png\")\n",
    "    gradient = np.linspace(0, 1, example_heatmap.shape[1]).reshape(1, -1)\n",
    "    gradient = np.vstack([gradient] * 50)  # Create a scale bar\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 1.4))\n",
    "    im = ax.imshow(gradient, aspect=\"auto\", cmap=\"jet\", origin=\"lower\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Position texts outside the bar\n",
    "    # \"Low\" to the left, \"High\" to the right\n",
    "    # We'll slightly adjust the plot limits to allow space\n",
    "    ax.set_xlim(-0.001*example_heatmap.shape[1], 1.0001*example_heatmap.shape[1])\n",
    "    # The image is from 0 to example_heatmap.shape[1]-1 in x-axis. \n",
    "    # We'll place Low at a negative x and High at beyond the length.\n",
    "    low_x = - (0.05 * example_heatmap.shape[1])\n",
    "    high_x = (1.01 * example_heatmap.shape[1])\n",
    "    mid_y = 25  # middle in the vertical direction (since height=50)\n",
    "    ax.text(low_x, mid_y, 'Low', va='center', ha='right', fontsize=20)\n",
    "    ax.text(high_x, mid_y, 'High', va='center', ha='left', fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(scale_bar_path, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    return scale_bar_path\n",
    "\n",
    "def create_legend_arrows(save_dir):\n",
    "    \"\"\"\n",
    "    Creates an image with two arrows facing right (stacked vertically) and text below each arrow.\n",
    "    Uses plt.arrow so that the legend arrows match the plot arrows.\n",
    "    The arrows are now wider and shorter.\n",
    "    \"\"\"\n",
    "    legend_arrows_path = os.path.join(save_dir, \"legend_arrows.png\")\n",
    "\n",
    "    plt.figure(figsize=(3, 1.4))\n",
    "    \n",
    "    # Ground Truth Arrow (Green with black outline)\n",
    "    # plt.arrow(\n",
    "    #     0.1, 0.6,    # starting point (x, y)\n",
    "    #     0.2, 0,       # dx, dy (arrow extends from x=0.1 to 0.3, making it shorter than before)\n",
    "    #     width=0.1,   # increased width for a thicker (wider) arrow shaft\n",
    "    #     head_width=0.24,  # larger arrowhead to match the increased width\n",
    "    #     head_length=0.08, # shorter head length, keeping proportion with the overall shorter arrow\n",
    "    #     fc='green',\n",
    "    #     ec='black',\n",
    "    #     length_includes_head=True\n",
    "    # )\n",
    "    # Text label next to the Ground Truth arrow\n",
    "    plt.text(0.32, 0.6, \"Ground Truth\", color='black', fontsize=16,\n",
    "             ha='left', va='center')\n",
    "\n",
    "    # Predicted Arrow (White with black outline)\n",
    "    # plt.arrow(\n",
    "    #     0.1, 0.3,    # starting point (x, y)\n",
    "    #     0.2, 0,       # dx, dy (arrow extends from x=0.1 to 0.3)\n",
    "    #     width=0.1,   # wider arrow shaft\n",
    "    #     head_width=0.24,\n",
    "    #     head_length=0.08,\n",
    "    #     fc='white',\n",
    "    #     ec='black',\n",
    "    #     length_includes_head=True\n",
    "    # )\n",
    "    # Text label next to the Predicted arrow\n",
    "    plt.text(0.32, 0.3, \"Predicted\", color='black', fontsize=16,\n",
    "             ha='left', va='center')\n",
    "\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(legend_arrows_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    return legend_arrows_path\n",
    "\n",
    "\n",
    "def generate_maps_and_latex(scene_dir, prob_vol_dir, save_dir, poses, num_cameras=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Generates heatmaps and creates a LaTeX table with accuracy metrics.\n",
    "    \"\"\"\n",
    "    scene_save_dir = os.path.join(save_dir, f\"figures/examples/{os.path.basename(scene_dir)}\")\n",
    "    os.makedirs(scene_save_dir, exist_ok=True)\n",
    "\n",
    "    # Ensure floorplan_semantic.png is present\n",
    "    floorplan_src = os.path.join(scene_dir, \"floorplan_semantic.png\")\n",
    "    floorplan_dest = os.path.join(scene_save_dir, \"floorplan_semantic.png\")\n",
    "    if not os.path.exists(floorplan_src):\n",
    "        raise FileNotFoundError(f\"floorplan_semantic.png not found in {scene_dir}\")\n",
    "    if not os.path.exists(floorplan_dest):\n",
    "        shutil.copy(floorplan_src, floorplan_dest)\n",
    "\n",
    "    heatmaps = []\n",
    "    for file_name in os.listdir(prob_vol_dir):\n",
    "        if file_name.endswith(\"pred_depth_prob_vol.pt.gz\"):\n",
    "            file_path = os.path.join(prob_vol_dir, file_name)\n",
    "            depth_prob_vol = load_compressed_tensor(file_path)\n",
    "\n",
    "            semantic_file_name = file_name.replace(\"pred_depth_prob_vol.pt.gz\", \"pred_semantic_prob_vol.pt.gz\")\n",
    "            semantic_file_path = os.path.join(prob_vol_dir, semantic_file_name)\n",
    "\n",
    "            if os.path.exists(semantic_file_path):\n",
    "                semantic_prob_vol = load_compressed_tensor(semantic_file_path)\n",
    "\n",
    "                combined_prob_vol = 0.5 * depth_prob_vol + 0.5 * semantic_prob_vol\n",
    "                heatmaps.append((file_name, depth_prob_vol, semantic_prob_vol, combined_prob_vol))\n",
    "\n",
    "    heatmaps.sort(key=lambda x: extract_camera_number(x[0]))\n",
    "    heatmaps = heatmaps[:num_cameras]\n",
    "\n",
    "    # Create the scale bar using one of the heatmaps\n",
    "    example_heatmap = heatmaps[0][1] if heatmaps else np.random.rand(10, 10)  # Use depth_prob_vol\n",
    "    scale_bar_path = create_scale_bar(scene_save_dir, example_heatmap)\n",
    "\n",
    "    # Create the arrows image\n",
    "    legend_arrows_path = create_legend_arrows(scene_save_dir)\n",
    "\n",
    "    output_images = []\n",
    "    metrics = []  # Store accuracy metrics for each plot\n",
    "    camera_images = []\n",
    "    for i, (file_name, depth_prob_vol, semantic_prob_vol, combined_prob_vol) in enumerate(heatmaps):\n",
    "        ref_pose_map = poses[i] if i < len(poses) else None\n",
    "\n",
    "        # Extract camera number\n",
    "        camera_number = extract_camera_number(file_name)\n",
    "        camera_path = os.path.join(scene_dir, \"rgb\", f\"{camera_number}.png\")\n",
    "\n",
    "        # Generate plots and calculate metrics\n",
    "        depth_map_path = os.path.join(scene_save_dir, f\"depth_map_{i}.png\")\n",
    "        depth_acc, depth_acc_orn = plot_single_map(depth_prob_vol, ref_pose_map, 0.1, depth_map_path, device)\n",
    "\n",
    "        semantic_map_path = os.path.join(scene_save_dir, f\"semantic_map_{i}.png\")\n",
    "        semantic_acc, semantic_acc_orn = plot_single_map(semantic_prob_vol, ref_pose_map, 0.1, semantic_map_path, device)\n",
    "\n",
    "        combined_map_path = os.path.join(scene_save_dir, f\"combined_map_{i}.png\")\n",
    "        combined_acc, combined_acc_orn = plot_single_map(combined_prob_vol, ref_pose_map, 0.1, combined_map_path, device)\n",
    "\n",
    "        metrics.append([\n",
    "            (depth_acc, depth_acc_orn),\n",
    "            (semantic_acc, semantic_acc_orn),\n",
    "            (combined_acc, combined_acc_orn)\n",
    "        ])\n",
    "        output_images.append((depth_map_path, semantic_map_path, combined_map_path))\n",
    "        camera_images.append(camera_path)\n",
    "\n",
    "    latex_content = r\"\"\"\n",
    "\\documentclass[a4paper]{article}\n",
    "\\usepackage{graphicx}\n",
    "\\usepackage[margin=0.5in]{geometry}\n",
    "\\usepackage{amsmath,amssymb}\n",
    "\\begin{document}\n",
    "\n",
    "\\begin{center}\n",
    "\\small\n",
    "\\begin{tabular}{ccccc}\n",
    "\\hline\n",
    "\\textbf{Camera} & \\textbf{Floor Plan} & \\textbf{Depth Map} & \\textbf{Semantic Map} & \\textbf{Combined Map} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "\n",
    "    floorplan_rel = f\"figures/examples/{os.path.basename(scene_dir)}/floorplan_semantic.png\"\n",
    "\n",
    "    for i, (depth_map_path, semantic_map_path, combined_map_path) in enumerate(output_images):\n",
    "        depth_acc, depth_acc_orn = metrics[i][0]\n",
    "        semantic_acc, semantic_acc_orn = metrics[i][1]\n",
    "        combined_acc, combined_acc_orn = metrics[i][2]\n",
    "\n",
    "        depth_info = f\"({depth_acc:.2f}m, {depth_acc_orn:.0f}^\\circ)\"\n",
    "        semantic_info = f\"({semantic_acc:.2f}m, {semantic_acc_orn:.0f}^\\circ)\"\n",
    "        combined_info = f\"({combined_acc:.2f}m, {combined_acc_orn:.0f}^\\circ)\"\n",
    "\n",
    "        camera_image_dest = os.path.join(scene_save_dir, f\"camera_{i}.png\")\n",
    "        if not os.path.exists(camera_image_dest):\n",
    "            shutil.copy(camera_images[i], camera_image_dest)\n",
    "        camera_rel = f\"figures/examples/{os.path.basename(scene_dir)}/camera_{i}.png\"\n",
    "\n",
    "        latex_content += f\"\"\"\n",
    "\\\\includegraphics[width=0.25\\\\textwidth]{{{camera_rel}}} &\n",
    "\\\\includegraphics[width=0.15\\\\textwidth]{{{floorplan_rel}}} &\n",
    "\\\\includegraphics[width=0.15\\\\textwidth]{{figures/examples/{os.path.basename(scene_dir)}/{os.path.basename(depth_map_path)}}} &\n",
    "\\\\includegraphics[width=0.15\\\\textwidth]{{figures/examples/{os.path.basename(scene_dir)}/{os.path.basename(semantic_map_path)}}} &\n",
    "\\\\includegraphics[width=0.15\\\\textwidth]{{figures/examples/{os.path.basename(scene_dir)}/{os.path.basename(combined_map_path)}}} \\\\\\\\\n",
    "\n",
    "& & {depth_info} & {semantic_info} & {combined_info} \\\\\\\\\n",
    "\\\\hline\n",
    "\"\"\"\n",
    "\n",
    "    # Add legend and scale bar right below the last image row\n",
    "    latex_content += r\"\"\"\n",
    "\\multicolumn{5}{c}{\n",
    "\\includegraphics[width=0.2\\textwidth]{figures/examples/\"\"\" + os.path.basename(scene_dir) + r\"\"\"/scale_bar.png}\n",
    "\\hspace{1em}\n",
    "\\includegraphics[width=0.2\\textwidth]{figures/examples/\"\"\" + os.path.basename(scene_dir) + r\"\"\"/legend_arrows.png}\n",
    "} \\\\\n",
    "\\end{tabular}\n",
    "\\end{center}\n",
    "\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "\n",
    "    latex_file = os.path.join(scene_save_dir, \"output_table.tex\")\n",
    "    with open(latex_file, \"w\") as f:\n",
    "        f.write(latex_content)\n",
    "\n",
    "\n",
    "# Example usage (adapt paths if needed)\n",
    "# scene_name = \"scene_1068_floor_01\"\n",
    "# save_dir = \"/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/results/final_results/zind/visualtizations/saved_maps\"\n",
    "# scene_dir = f\"/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/zind/zind_data_set_80_fov/{scene_name}\"\n",
    "# prob_vol_dir = f\"/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/zind/prob_vol/{scene_name}\"\n",
    "scene_name = \"scene_3300\"\n",
    "save_dir = \"/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/results/final_results/visualtizations/saved_maps\"\n",
    "scene_dir = f\"/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/test_data_set_full/structured3d_perspective_full/{scene_name}\"\n",
    "prob_vol_dir = f\"/datadrive2/CRM.AI.Research/TeamFolders/Email/repo_yuval/FloorPlan/Semantic_Floor_plan_localization/data/test_data_set_full/prob_vols/{scene_name}\"\n",
    "poses_file = os.path.join(scene_dir, \"poses.txt\")\n",
    "poses = read_poses(poses_file)\n",
    "generate_maps_and_latex(scene_dir, prob_vol_dir, save_dir, poses, num_cameras=50, device='cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
